{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5096ee85-a0d8-40aa-abf1-406ccee32daf",
   "metadata": {},
   "source": [
    "# New Relic ML Performance Monitoring- Bring Your Own Data\n",
    "##### “Add your own data” is a library-based of the “newrelic_telemetry_sdk” <br> library that helps the user easily send model data to New Relic,<br> so that they can quickly monitor a simple model, directly from a Jupyter notebook or a cloud service. \n",
    "##### in the following notebook, you will see a various ways to use it.\n",
    "\n",
    "note:\n",
    "this notebook use the libraries: sklearn, pandas, uuid, xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf23f3-4ab0-4e52-9c3a-5c150590cc39",
   "metadata": {},
   "source": [
    "### 1. Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57ee9c03-5043-4a26-94e6-5924cf549cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_relic_ml_performance_monitoring.monitor import (\n",
    "    MLPerformanceMonitoring,\n",
    "    wrap_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432798ef-1fb1-4006-9510-84c4778454a9",
   "metadata": {},
   "source": [
    "### 2. Load the iris dataset and split it into train and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "302cf098-c363-4989-90a7-1947340eebc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212217d-1573-4ccd-98e0-3725800d8274",
   "metadata": {},
   "source": [
    "### 3. Fitting Random Forest Classification to the Training set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb62a1bb-28ea-4105-93be-62d0a4c8deaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    n_estimators=10, criterion=\"entropy\", random_state=0\n",
    ")\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5c717-58d3-4b41-88c3-549a044d7d7d",
   "metadata": {},
   "source": [
    "### 4. Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bcced287-1691-4fd3-a802-bea65f5edf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 0, 1,\n",
       "       0, 2, 0, 0, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66de2b-e106-4a81-a5f8-83fb252e55fd",
   "metadata": {},
   "source": [
    "### 5. Record inference data to New Relic\n",
    "#####  The MLPerformanceMonitoring object requires few parameters:<br> 1.model_name <br> 2.new relic insert key-https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/#insights-insert-key <br>\n",
    "##### Optional parameters:<br> 3.metadata dictonrary that will be added to each event (row) of the data<br>4.send_data_metrics- send datafame sammary to New Relic. False as defualt.  <br>5.features_columns- list of the features names in the same order as X<br>6.labels_columns- list of the labels names in the same order as y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b74dc293-03cb-4e05-99c2-fc88a3c513a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/vy1ftggn3kdfnd9cjmwt_nc40000gn/T/ipykernel_48300/3584282852.py:48: UserWarning: model wasn't defined, please use 'record_inference_data' to send data\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metadata = {\"environment\": \"aws\", \"dataset\": \"iris\", \"version\": \"1.0\"}\n",
    "monitor = MLPerformanceMonitoring(\n",
    "    model_name=\"Iris RandomForestClassifier\",\n",
    "    insert_key=insert_key,\n",
    "    metadata=metadata,\n",
    "    send_data_metrics=True,\n",
    "    features_columns=[\n",
    "        \"sepal_length\",\n",
    "        \"sepal_width\",\n",
    "        \"petal_length\",\n",
    "        \"petal_width\",\n",
    "    ],\n",
    "    labels_columns=[\"species\"],\n",
    "    staging=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ee01e-c2ad-4c38-a870-6017d065a7e6",
   "metadata": {},
   "source": [
    "#####  You can use the MLPerformanceMonitoring object in vairios ways:\n",
    "##### 5.1.  Send your features and prediction as np.array. <br> In this case, the feature columns and the label columns  in new relic will be start with the prefix \"feature_\" and \"lablel_\" with numbers, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a7f58174-be3d-4801-861f-1b53797f413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data sent successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/vy1ftggn3kdfnd9cjmwt_nc40000gn/T/ipykernel_48300/3584282852.py:167: UserWarning: inference identifier wasn't defined\n",
      "  warnings.warn(\"inference identifier wasn't defined\")\n",
      "/var/folders/cr/vy1ftggn3kdfnd9cjmwt_nc40000gn/T/ipykernel_48300/3584282852.py:201: UserWarning: send_data_metrics occurs only when there are at least 100 rows\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "monitor.record_inference_data(X=X_test, y=y_pred, data_summary_min_rows=len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b0c6d-7c87-495e-92ae-91f3ea8f4f7f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### 5.2.  Send your features and prediction as pd.DataFrame. <br> In this case, the feature columns and the label columns in new relic will be the DataFrame columns names and will be start with the prefix \"feature_\" and \"lablel_\", respectively. <br> The paramter \"inference_identifier\" can be use of setting a unique inference_identifier for each event(row). Just set the relevent column name in the X DataFrame that need to be used as inference_identifier and this column will be name \"inference_identifier\" in New Relic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07a8a252-675f-4f17-a325-6c940a0ad4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           6.3          2.5           4.9          1.5\n",
       "1           6.8          3.0           5.5          2.1\n",
       "2           6.4          2.8           5.6          2.2\n",
       "3           5.6          3.0           4.1          1.3\n",
       "4           4.9          3.6           1.4          0.1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(\n",
    "    list(map(np.ravel, X_test)),\n",
    "    columns=[\n",
    "        \"sepal_length\",\n",
    "        \"sepal_width\",\n",
    "        \"petal_length\",\n",
    "        \"petal_width\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "y_pred_df = pd.DataFrame(\n",
    "    list(map(np.ravel, y_pred)),\n",
    "    columns=[\"species\"],\n",
    ")\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c8f58775-0e59-4689-8c9c-48a8704ad0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species\n",
       "0        1\n",
       "1        2\n",
       "2        2\n",
       "3        1\n",
       "4        0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ea4934d-ff1b-444a-9770-8f47025ef027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data sent successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/vy1ftggn3kdfnd9cjmwt_nc40000gn/T/ipykernel_48300/3584282852.py:201: UserWarning: send_data_metrics occurs only when there are at least 100 rows\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>a54b6946-bd78-4168-82ca-920062791f71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ccffa32d-adc5-41fe-ad42-bc43a4e2324b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8956305c-8702-4e48-8fd3-8504a1ea8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>d2130f15-33e1-4d3f-b43a-7658088e9b8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>dbf0bb9e-575e-46a7-b7cc-29b2e164ae9f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "0           6.3          2.5           4.9          1.5   \n",
       "1           6.8          3.0           5.5          2.1   \n",
       "2           6.4          2.8           5.6          2.2   \n",
       "3           5.6          3.0           4.1          1.3   \n",
       "4           4.9          3.6           1.4          0.1   \n",
       "\n",
       "                                   uuid  \n",
       "0  a54b6946-bd78-4168-82ca-920062791f71  \n",
       "1  ccffa32d-adc5-41fe-ad42-bc43a4e2324b  \n",
       "2  8956305c-8702-4e48-8fd3-8504a1ea8794  \n",
       "3  d2130f15-33e1-4d3f-b43a-7658088e9b8b  \n",
       "4  dbf0bb9e-575e-46a7-b7cc-29b2e164ae9f  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "X_df[\"uuid\"] = X_df.apply(lambda _: str(uuid.uuid4()), axis=1)\n",
    "\n",
    "monitor.record_inference_data(\n",
    "    X=X_df, y=y_pred_df, inference_identifier=\"uuid\", calling_method=\"predict\"\n",
    ")\n",
    "\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd573a-d4f7-401f-b236-86ca04d4d4ee",
   "metadata": {},
   "source": [
    "##### 5.3.  Use wrap_model() function to send your model or pipelin as parameter and use them as usual (fit, predict, ect.). This function will send your inference data and data_metrics automaticlly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c47330c-73f3-4bad-a6c9-6aa061d8d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data sent successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syehezkel/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "monitor_model = wrap_model(\n",
    "    model_name=\"Iris RandomForestClassifier\",\n",
    "    insert_key=insert_key,\n",
    "    metadata=metadata,\n",
    "    staging=True,\n",
    "    model=classifier,\n",
    ")\n",
    "y_pred = monitor_model.predict(\n",
    "    X=X_df,\n",
    "    inference_identifier=\"uuid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "692a2c53-86d4-45ee-a350-200d97cf5bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data sent successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/vy1ftggn3kdfnd9cjmwt_nc40000gn/T/ipykernel_48300/3584282852.py:167: UserWarning: inference identifier wasn't defined\n",
      "  warnings.warn(\"inference identifier wasn't defined\")\n"
     ]
    }
   ],
   "source": [
    "# from new_relic_ml_performance_monitoring.monitor import wrap_model\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set up a pipeline with a feature selection preprocessor that\n",
    "# selects the top 2 features to use.\n",
    "# The pipeline then uses a RandomForestClassifier to train the model.\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"feature_selection\", SelectKBest(chi2, k=2)),\n",
    "        (\"classification\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "metadata = {\"environment\": \"aws\", \"dataset\": \"iris\", \"version\": \"1.0\"}\n",
    "pipeline = wrap_model(\n",
    "    insert_key=insert_key,\n",
    "    model=pipeline,\n",
    "    staging=True,\n",
    "    model_name=\"Iris RandomForestClassifier\",\n",
    "    metadata=metadata,\n",
    ")\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b4080-8b46-4c71-9834-7ffc60cfad73",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### 6. Record metrics to New Relic\n",
    "#####  \n",
    "\n",
    "Send your model metrics as a dictionary to new relic. You can send new metadata or the fuction use the metadata you set in the object creation. Also, a boolean parameter named \"data_metric\" can be used to idenify is those metrics are data metric (like mean and std of each feature) or model metrics (like accuracy and f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc20d627-9357-498f-a609-81636bb20358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    :  1.0\n",
      "Recall      :  1.0\n",
      "Precision   :  1.0\n",
      "F1 Score    :  1.0\n",
      "model_metric sent successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# Model Evaluation\n",
    "ac_sc = accuracy_score(y_test, y_pred)\n",
    "rc_sc = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "pr_sc = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "f1_sc = f1_score(y_test, y_test, average=\"micro\")\n",
    "\n",
    "print(f\"Accuracy    : {ac_sc}\")\n",
    "print(f\"Recall      : {rc_sc}\")\n",
    "print(f\"Precision   : {pr_sc}\")\n",
    "print(f\"F1 Score    : {f1_sc}\")\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": ac_sc,\n",
    "    \"Recall\": rc_sc,\n",
    "    \"Precision\": pr_sc,\n",
    "    \"F1 Score\": f1_sc,\n",
    "}\n",
    "metrics\n",
    "pipeline.record_metrics(metrics=metrics, data_metric=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
