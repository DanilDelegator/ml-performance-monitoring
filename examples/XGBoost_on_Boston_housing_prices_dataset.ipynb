{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5096ee85-a0d8-40aa-abf1-406ccee32daf",
   "metadata": {},
   "source": [
    "# New Relic ML Performance Monitoring- Bring Your Own Data\n",
    "<b> “ML Performance Monitoring” is a library based on the “newrelic_telemetry_sdk” library that helps the user easily send model data to New Relic,so that they can quickly monitor a simple model, directly from a Jupyter notebook or a cloud service. \n",
    "In the following notebook, you will see a various ways to use it.</b> \n",
    "\n",
    "Note:\n",
    "this notebook use the libraries: sklearn, pandas, uuid, numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf23f3-4ab0-4e52-9c3a-5c150590cc39",
   "metadata": {},
   "source": [
    "### 1. Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ee9c03-5043-4a26-94e6-5924cf549cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from new_relic_ml_performance_monitoring.monitor import (\n",
    "    MLPerformanceMonitoring,\n",
    "    wrap_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432798ef-1fb1-4006-9510-84c4778454a9",
   "metadata": {},
   "source": [
    "### 2. Load the iris dataset and split it into train and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cf098-c363-4989-90a7-1947340eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "X, y, features_columns, labels_columns = (\n",
    "    boston_dataset[\"data\"],\n",
    "    boston_dataset[\"target\"],\n",
    "    list(boston_dataset[\"feature_names\"]),\n",
    "    [\"target\"],\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212217d-1573-4ccd-98e0-3725800d8274",
   "metadata": {},
   "source": [
    "### 3. Fitting Random Forest Classification to the Training set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb62a1bb-28ea-4105-93be-62d0a4c8deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:23:54] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=10, n_jobs=16,\n",
       "             num_parallel_tree=1, objective='reg:linear', predictor='auto',\n",
       "             random_state=0, reg_alpha=10, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:linear\",\n",
    "    colsample_bytree=0.3,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    alpha=10,\n",
    "    n_estimators=10,\n",
    ")\n",
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5c717-58d3-4b41-88c3-549a044d7d7d",
   "metadata": {},
   "source": [
    "### 4. Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcced287-1691-4fd3-a802-bea65f5edf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.107417 , 17.003168 , 23.554592 , 11.127839 , 18.847708 ,\n",
       "       14.83594  , 17.920063 ,  7.8613553, 12.147531 , 18.064953 ,\n",
       "       18.074614 , 14.411147 , 11.660895 , 15.656607 , 14.011221 ,\n",
       "       14.031893 , 14.247164 , 23.057888 , 13.79595  , 11.450888 ,\n",
       "       12.218057 , 15.310874 , 20.628437 , 23.554592 , 15.16144  ,\n",
       "       13.139177 , 11.691522 , 15.382896 , 15.382896 , 11.007488 ,\n",
       "       14.734173 , 18.862646 ,  8.471523 , 15.349405 , 15.463427 ,\n",
       "       19.77869  , 15.875313 ,  9.95701  , 12.919248 , 23.60624  ,\n",
       "       18.295853 , 12.589657 , 14.179869 , 21.97658  , 12.664099 ,\n",
       "       16.489174 , 14.038502 , 15.660043 , 12.919248 , 14.453838 ,\n",
       "       18.862646 , 17.252022 , 14.038502 ,  7.9073224, 14.332668 ,\n",
       "       10.871179 , 10.826269 ,  8.5319   , 19.534363 ,  8.196141 ,\n",
       "       12.403829 , 14.235118 , 10.42806  , 13.162136 , 14.247164 ,\n",
       "       15.931118 , 16.565668 ,  9.804545 , 14.915205 , 18.295853 ,\n",
       "       13.15519  , 15.318869 , 12.919248 , 16.430174 , 11.854328 ,\n",
       "       12.32626  , 11.756507 , 14.426096 , 18.501059 ,  9.180772 ,\n",
       "       19.065006 ,  8.588221 , 15.463427 , 14.011221 , 12.898891 ,\n",
       "       15.079189 , 11.267364 , 15.272911 , 14.247164 , 19.482258 ,\n",
       "        9.210783 , 18.699503 , 13.79595  , 15.878302 , 19.92443  ,\n",
       "       17.05043  , 11.450888 , 20.330242 , 16.072117 , 20.87532  ,\n",
       "       14.714855 , 11.429612 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xg_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66de2b-e106-4a81-a5f8-83fb252e55fd",
   "metadata": {},
   "source": [
    "### 5. Record inference data to New Relic\n",
    "<b>   The MLPerformanceMonitoring object requires few parameters:<br> 1. model_name <br> 2. new relic insert key-https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/#insights-insert-key <br>\n",
    "##### Optional parameters:<br> 3. metadata dictonrary that will be added to each event (row) of the data<br>4. send_data_metrics- send datafame sammary to New Relic. False as defualt.  <br>5. features_columns- list of the features names in the same order as X<br>6.labels_columns- list of the labels names in the same order as y </b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74dc293-03cb-4e05-99c2-fc88a3c513a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"environment\": \"aws\", \"dataset\": \"Boston housing prices\", \"version\": \"1.0\"}\n",
    "monitor = wrap_model(\n",
    "    insert_key=insert_key,\n",
    "    model=xg_reg,\n",
    "    staging=True,\n",
    "    model_name=\"Boston XGBoost regression\",  # the model_name value must be unique per model\n",
    "    metadata=metadata,\n",
    "    send_data_metrics=True,\n",
    "    features_columns=features_columns,\n",
    "    labels_columns=labels_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ee01e-c2ad-4c38-a870-6017d065a7e6",
   "metadata": {},
   "source": [
    "<b>   You can use the MLPerformanceMonitoring object in vairios ways:\n",
    "<br> 5.1.  Send your features and prediction as np.array. <br> In this case, the feature columns and the label columns  in new relic will be start with the prefix \"feature_\" and \"lablel_\" with numbers, respectively.</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f58174-be3d-4801-861f-1b53797f413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.record_inference_data(X=X_test, y=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b0c6d-7c87-495e-92ae-91f3ea8f4f7f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "<b> 5.2.  Send your features and prediction as pd.DataFrame. <br> In this case, the feature columns and the label columns in new relic will be the DataFrame columns names and will be start with the prefix \"feature_\" and \"lablel_\", respectively. <br> The paramter \"inference_identifier\" can be use of setting a unique inference_identifier for each event(row). Just set the relevent column name in the X DataFrame that need to be used as inference_identifier and this column will be name \"inference_identifier\" in New Relic. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a8a252-675f-4f17-a325-6c940a0ad4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.13580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>5.757</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4130</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.60</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>6.630</td>\n",
       "      <td>56.1</td>\n",
       "      <td>4.4377</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>392.30</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03578</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>7.820</td>\n",
       "      <td>64.5</td>\n",
       "      <td>4.6947</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>387.31</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.04820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.648</td>\n",
       "      <td>87.6</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>291.55</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03150</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>6.975</td>\n",
       "      <td>15.3</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS     NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0  51.13580   0.0  18.10   0.0  0.5970  5.757  100.0  1.4130  24.0  666.0   \n",
       "1   0.05735   0.0   4.49   0.0  0.4490  6.630   56.1  4.4377   3.0  247.0   \n",
       "2   0.03578  20.0   3.33   0.0  0.4429  7.820   64.5  4.6947   5.0  216.0   \n",
       "3  12.04820   0.0  18.10   0.0  0.6140  5.648   87.6  1.9512  24.0  666.0   \n",
       "4   0.03150  95.0   1.47   0.0  0.4030  6.975   15.3  7.6534   3.0  402.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     20.2    2.60  10.11  \n",
       "1     18.5  392.30   6.53  \n",
       "2     14.9  387.31   3.76  \n",
       "3     20.2  291.55  14.10  \n",
       "4     17.0  396.90   4.56  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(\n",
    "    list(map(np.ravel, X_test)),\n",
    "    columns=features_columns,\n",
    ")\n",
    "\n",
    "y_pred_df = pd.DataFrame(\n",
    "    list(map(np.ravel, y_pred)),\n",
    "    columns=labels_columns,\n",
    ")\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f58775-0e59-4689-8c9c-48a8704ad0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.107417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.554592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.127839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.847708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0   9.107417\n",
       "1  17.003168\n",
       "2  23.554592\n",
       "3  11.127839\n",
       "4  18.847708"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4934d-ff1b-444a-9770-8f47025ef027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "X_df[\"uuid\"] = X_df.apply(lambda _: str(uuid.uuid4()), axis=1)\n",
    "\n",
    "monitor.record_inference_data(X=X_df, y=y_pred_df, inference_identifier=\"uuid\")\n",
    "\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd573a-d4f7-401f-b236-86ca04d4d4ee",
   "metadata": {},
   "source": [
    "<b> 5.3.  Use wrap_model() function to send your model or pipelin as parameter and use them as usual (fit, predict, ect.). This function will send your inference data and data_metrics automaticlly. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47330c-73f3-4bad-a6c9-6aa061d8d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"environment\": \"aws\", \"dataset\": \"Boston housing prices\", \"version\": \"1.0\"}\n",
    "model = wrap_model(\n",
    "    insert_key=insert_key,\n",
    "    model=xg_reg,\n",
    "    staging=True,\n",
    "    model_name=\"Boston XGBoost regression\",\n",
    "    metadata=metadata,\n",
    "    send_data_metrics=True,\n",
    "    features_columns=features_columns,\n",
    "    labels_columns=labels_columns,\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model.predict(\n",
    "    X=X_df,\n",
    "    inference_identifier=\"uuid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f6a23-8f3c-43e1-bfb2-54db1533afc3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### 6. Record metrics to New Relic\n",
    "\n",
    "<b>Send your model metrics as a dictionary to new relic. You can send new metadata or the fuction use the metadata you set in the object creation. Also, a boolean parameter named \"data_metric\" can be used to idenify is those metrics are data metric (like mean and std of each feature) or model metrics (like accuracy and f1 score)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc20d627-9357-498f-a609-81636bb20358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.517\n"
     ]
    }
   ],
   "source": [
    "rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5838587-4269-4cb2-8c8b-53e2c47d83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_metric sent successfully\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "}\n",
    "model.record_metrics(metrics=metrics, data_metric=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
